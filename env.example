# LLM API 配置
LLM_API_BASE_URL=https://api.openai.com/v1
LLM_API_KEY=your-api-key-here

# 模型配置
LLM_DEFAULT_MODEL=qwen-flash
# 支持的模型列表（用逗号分隔，如果未设置则使用默认列表）
# LLM_SUPPORTED_MODELS=qwen-flash
# 是否启用模型验证（默认：true）
# LLM_ENABLE_MODEL_VALIDATION=true

# 模型默认参数
LLM_DEFAULT_TEMPERATURE=0.7
LLM_DEFAULT_MAX_TOKENS=2000
LLM_DEFAULT_TOP_P=1.0
LLM_DEFAULT_FREQUENCY_PENALTY=0.0
LLM_DEFAULT_PRESENCE_PENALTY=0.0

# 服务配置
PORT=3000
NODE_ENV=development

# 可选：API 限流配置
RATE_LIMIT_MAX_REQUESTS=100
RATE_LIMIT_WINDOW_MS=60000

